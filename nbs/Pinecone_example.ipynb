{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ss1qxe4kVOp"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install -qU openai pinecone-client datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_2n0rDlgvpr"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J94OgqkpfrkN"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qDwphzakbrG"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "openai.api_key = \"YOUR_OPEN_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "mkG_HzXCk_qs",
    "outputId": "be551215-622b-4fe5-d7ae-8996e553f4c3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Andrey Kolmogorov (1903-1987) was a Russian mathematician and one of the most influential mathematicians of the 20th century. He made significant contributions to the fields of probability theory, topology, and mathematical analysis. He is best known for his work on the theory of probability, which laid the foundations for modern probability theory. He also developed the theory of Kolmogorov complexity, which is used in computer science. He worked from the 1920s until his death in 1987.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who was Kolmogorov and when did he work?\"\n",
    "\n",
    "# now query text-davinci-003 WITHOUT context\n",
    "res = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=query,\n",
    "    temperature=0,\n",
    "    max_tokens=400,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "res['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sB7ZdgcHlEwf"
   },
   "outputs": [],
   "source": [
    "def complete(prompt):\n",
    "    # query text-davinci-003\n",
    "    res = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=400,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return res['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "lMcpK838l7qe",
    "outputId": "0a1c084c-b3d3-430f-858e-a76389db438a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'If you only have pairs of related sentences, then the best training method to use for sentence transformers is the supervised learning approach. This approach involves providing the model with labeled data, such as pairs of related sentences, and then training the model to learn the relationships between the sentences. This approach is often used for tasks such as natural language inference, semantic similarity, and paraphrase identification.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = (\n",
    "    \"Which training method should I use for sentence transformers when \" +\n",
    "    \"I only have pairs of related sentences?\"\n",
    ")\n",
    "\n",
    "complete(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6JPwYLGmA9g",
    "outputId": "f2087612-b31c-46ce-a94b-55ddfb12b61b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/jamescalam___json/jamescalam--youtube-transcriptions-08d889f6a5386b9b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'published', 'url', 'video_id', 'channel_id', 'id', 'text', 'start', 'end'],\n",
       "    num_rows: 208619\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('jamescalam/youtube-transcriptions', split='train')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRMj4trbmTZN",
    "outputId": "bb6d7549-1d56-403f-866b-f942f7cebdd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'video_id': '35Pdoyi6ZoQ',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       " 'id': '35Pdoyi6ZoQ-t3.0',\n",
       " 'text': 'So this is the fourth video in a Transformers',\n",
       " 'start': 3.0,\n",
       " 'end': 11.56}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "accf79d761fc4725bb64039726cddc3a",
      "5c04633ddfd94e249f694899e7fe92c1",
      "aabf2644c2cc4066b968e3b0e5688015",
      "6e690f5786944587a13c8d40a4845422",
      "f6f4e8bdf99c4fc2938842cbcdcf47b8",
      "22d5607a80914565b9dd156f5886aa25",
      "eed090baffd24e7ca840fa288319d6e5",
      "822165b974a141e2a3096426cec62fd5",
      "d08ca546c039454e870e447ba29a39b4",
      "84a5fd78892943f49ff5ef20bd9b71a2",
      "74d760f96f6241efbd576ad6b4519ba0"
     ]
    },
    "id": "qJ0df5-4mYNR",
    "outputId": "4b04a248-0cb2-4f39-9c8a-ac6166786f04"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accf79d761fc4725bb64039726cddc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "new_data = []\n",
    "\n",
    "window = 20  # number of sentences to combine\n",
    "stride = 4  # number of sentences to 'stride' over, used to create overlap\n",
    "\n",
    "for i in tqdm(range(0, len(data), stride)):\n",
    "    i_end = min(len(data)-1, i+window)\n",
    "    if data[i]['title'] != data[i_end]['title']:\n",
    "        # in this case we skip this entry as we have start/end of two videos\n",
    "        continue\n",
    "    text = ' '.join(data[i:i_end]['text'])\n",
    "    # create the new merged dataset\n",
    "    new_data.append({\n",
    "        'start': data[i]['start'],\n",
    "        'end': data[i_end]['end'],\n",
    "        'title': data[i]['title'],\n",
    "        'text': text,\n",
    "        'id': data[i]['id'],\n",
    "        'url': data[i]['url'],\n",
    "        'published': data[i]['published'],\n",
    "        'channel_id': data[i]['channel_id']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZB1Wn_WmfMu",
    "outputId": "b9aa89d4-cd22-4172-a326-6d355b09702f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 15.84,\n",
       " 'end': 88.75999999999999,\n",
       " 'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'text': \"we've essentially covered what you can see on the screen. So we got some data. We built a tokenizer with it. And then we've set up our input pipeline ready to begin actually training our model, which is what we're going to cover in this video. So let's move over to the code. And we see here that we have essentially everything we've done so far. So we've built our input data, our input pipeline. And we're now at a point where we have a data loader, PyTorch data loader, ready. And we can begin training a model with it. So there are a few things to be aware of. So I mean, first, let's just have a quick look at the structure of our data. So when we're training a model for mass language modeling, we need a few tensors. We need three tensors. And this is for training Roberta, by the way, as well.\",\n",
       " 'id': '35Pdoyi6ZoQ-t15.84',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgfegPtbpZRE"
   },
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWbRXbuAouad",
    "outputId": "acc06647-f816-4955-dafa-a6e540648b37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_S9WELynz3x",
    "outputId": "a34b90f9-abd2-49cf-d88e-f18dc091b521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'openai-youtube-transcriptions'\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=\"API_KEY\",\n",
    "    environment=\"asia-southeast1-gcp-free\"  # may be different, check at app.pinecone.io\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='cosine',\n",
    "        metadata_config={'indexed': ['channel_id', 'published']}\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7m1cRWbdog_E"
   },
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTUD1xEhq2MN",
    "outputId": "def4d228-abb9-470c-8073-ed5f04f74464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDFbLAAVq8TZ",
    "outputId": "90429ec7-9a0d-45dc-d8fa-3f3730cdd000"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/jamescalam___json/jamescalam--youtube-transcriptions-08d889f6a5386b9b/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'published', 'url', 'video_id', 'channel_id', 'id', 'text', 'start', 'end'],\n",
       "    num_rows: 208619\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset('jamescalam/youtube-transcriptions', split='train')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmnVXq4fq_KS"
   },
   "outputs": [],
   "source": [
    "# data = load_dataset('Whispering-GPT/lex-fridman-podcast')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwlzSdIzrMzB",
    "outputId": "b7f4ab07-01f3-4d30-a309-6749389111d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'video_id': '35Pdoyi6ZoQ',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       " 'id': '35Pdoyi6ZoQ-t0.0',\n",
       " 'text': 'Hi, welcome to the video.',\n",
       " 'start': 0.0,\n",
       " 'end': 9.36}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "dd2eba11b1bf42258f01897da34ef0cb",
      "771f925fcd46415180dfbf9455532447",
      "fcd464cbac9945da8e158798466a26e7",
      "d00765b03f484b27b3f63beffccfa084",
      "1c7dd2b8ef20490ab51be86ebcf87661",
      "962d3ebb12f042f08325cb463824dba9",
      "fa3796ae730f4bb086280940b2b1219b",
      "efee0ce5457d48b2ac72398cf1a60f7d",
      "da6b5510d5c1486abe82f8453e602fe7",
      "ee29fa17894c46299513789a18b8ab2e",
      "1c7b5d36c2444b1ba2a1ea55a2aefc74"
     ]
    },
    "id": "1RT4n3GFzBDX",
    "outputId": "09d2e00a-d543-437b-fa13-0040e9e9ed14"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2eba11b1bf42258f01897da34ef0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "new_data = []\n",
    "\n",
    "window = 20  # number of sentences to combine\n",
    "stride = 4  # number of sentences to 'stride' over, used to create overlap\n",
    "\n",
    "for i in tqdm(range(0, len(data), stride)):\n",
    "    i_end = min(len(data)-1, i+window)\n",
    "    if data[i]['title'] != data[i_end]['title']:\n",
    "        # in this case we skip this entry as we have start/end of two videos\n",
    "        continue\n",
    "    text = ' '.join(data[i:i_end]['text'])\n",
    "    # create the new merged dataset\n",
    "    new_data.append({\n",
    "        'start': data[i]['start'],\n",
    "        'end': data[i_end]['end'],\n",
    "        'title': data[i]['title'],\n",
    "        'text': text,\n",
    "        'id': data[i]['id'],\n",
    "        'url': data[i]['url'],\n",
    "        'published': data[i]['published'],\n",
    "        'channel_id': data[i]['channel_id']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lWiNLoGPZOv",
    "outputId": "a1995787-f096-4548-f880-682d5bfe6bde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0.0,\n",
       " 'end': 74.12,\n",
       " 'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',\n",
       " 'text': \"Hi, welcome to the video. So this is the fourth video in a Transformers from Scratch mini series. So if you haven't been following along, we've essentially covered what you can see on the screen. So we got some data. We built a tokenizer with it. And then we've set up our input pipeline ready to begin actually training our model, which is what we're going to cover in this video. So let's move over to the code. And we see here that we have essentially everything we've done so far. So we've built our input data, our input pipeline. And we're now at a point where we have a data loader, PyTorch data loader, ready. And we can begin training a model with it. So there are a few things to be aware of. So I mean, first, let's just have a quick look at the structure of our data.\",\n",
       " 'id': '35Pdoyi6ZoQ-t0.0',\n",
       " 'url': 'https://youtu.be/35Pdoyi6ZoQ',\n",
       " 'published': '2021-07-06 13:00:03 UTC',\n",
       " 'channel_id': 'UCv83tO5cePwHMt1952IVVHw'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-kOV2X0uYVR",
    "outputId": "b28f0f34-1643-4914-ffcb-117955e74ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test']\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "# index_name = 'openai-youtube-transcriptions'\n",
    "index_name = 'test'\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=\"PINECONE_API_KEY\",\n",
    "    environment=\"asia-southeast1-gcp-free\"  # may be different, check at app.pinecone.io\n",
    ")\n",
    "print(pinecone.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu3J2jz21Kfv"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'test'\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=\"PINECONE_API_KEY\",  \n",
    "    environment=\"asia-southeast1-gcp-free\"  # may be different, check at app.pinecone.io\n",
    ")\n",
    "print(pinecone.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbgckWWkRR36",
    "outputId": "e161e83b-b872-4728-a339-4029ac8a621d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='cosine',\n",
    "        metadata_config={'indexed': ['channel_id', 'published']}\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "62e89b2b99dc45918e3e67e5feac836a",
      "bb9dbdd955ed4d82b3402f5d51932b3c",
      "473da0adee8f4896a89a6d33dd2e12c8",
      "4bb515e60f5d43fbaa5a619748532d53",
      "897595ff039c4a4eb780eadda659f379",
      "cf37292b079649b38c2dd2ba2f64971d",
      "c43283d0d53c44f8b7c0f52fd525e2d9",
      "3f55eca51936443cb73b993f926b664e",
      "13e2ece863ab4aafa2856609e4c638b9",
      "598d91ab711246869d3e7a762ed9fd96",
      "ed112f1498364d3f804649c010d7b00d"
     ]
    },
    "id": "SdTyfcgcRUJP",
    "outputId": "b8a54cef-65ee-4978-9feb-7ed2ceb2d997"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e89b2b99dc45918e3e67e5feac836a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(new_data), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(new_data), i+batch_size)\n",
    "    meta_batch = new_data[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'start': x['start'],\n",
    "        'end': x['end'],\n",
    "        'title': x['title'],\n",
    "        'text': x['text'],\n",
    "        'url': x['url'],\n",
    "        'published': x['published'],\n",
    "        'channel_id': x['channel_id']\n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZSGqqkBRXRd"
   },
   "outputs": [],
   "source": [
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=2, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUwO-DG72H7y",
    "outputId": "4644437e-a94f-409f-d3e5-cb6017ce8cc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'pNvujJ1XyeQ-t418.88',\n",
       "              'metadata': {'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       "                           'end': 568.4,\n",
       "                           'published': datetime.datetime(2021, 11, 24, 16, 24, 24, tzinfo=tzlocal()),\n",
       "                           'start': 418.88,\n",
       "                           'text': 'pairs of related sentences you can go '\n",
       "                                   'ahead and actually try training or '\n",
       "                                   'fine-tuning using NLI with multiple '\n",
       "                                   \"negative ranking loss. If you don't have \"\n",
       "                                   'that fine. Another option is that you have '\n",
       "                                   'a semantic textual similarity data set or '\n",
       "                                   'STS and what this is is you have so you '\n",
       "                                   'have sentence A here, sentence B here and '\n",
       "                                   'then you have a score from from 0 to 1 '\n",
       "                                   'that tells you the similarity between '\n",
       "                                   'those two scores and you would train this '\n",
       "                                   'using something like cosine similarity '\n",
       "                                   \"loss. Now if that's not an option and your \"\n",
       "                                   'focus or use case is on building a '\n",
       "                                   'sentence transformer for another language '\n",
       "                                   'where there is no current sentence '\n",
       "                                   'transformer you can use multilingual '\n",
       "                                   'parallel data. So what I mean by that is '\n",
       "                                   'so parallel data just means translation '\n",
       "                                   'pairs so if you have for example a English '\n",
       "                                   'sentence and then you have another '\n",
       "                                   'language here so it can it can be anything '\n",
       "                                   \"I'm just going to put XX and that XX is \"\n",
       "                                   'your target language you can fine-tune a '\n",
       "                                   'model using something called multilingual '\n",
       "                                   'knowledge distillation and what that does '\n",
       "                                   'is takes a monolingual model for example '\n",
       "                                   'in English and using those translation '\n",
       "                                   'pairs it distills the knowledge the '\n",
       "                                   'semantic similarity knowledge from that '\n",
       "                                   'monolingual English model into a '\n",
       "                                   'multilingual model which can handle both '\n",
       "                                   'English and your target language. So '\n",
       "                                   \"they're three options quite popular very \"\n",
       "                                   'common that you can go for and as a '\n",
       "                                   'supervised methods the chances are that '\n",
       "                                   'probably going to outperform anything you '\n",
       "                                   'do with unsupervised training at least for '\n",
       "                                   'now. So if none of those sound like '\n",
       "                                   'something',\n",
       "                           'title': 'Today Unsupervised Sentence Transformers, '\n",
       "                                    'Tomorrow Skynet (how TSDAE works)',\n",
       "                           'url': 'https://youtu.be/pNvujJ1XyeQ'},\n",
       "              'score': 0.865329921,\n",
       "              'values': []},\n",
       "             {'id': 'WS1uVMGhlWQ-t737.28',\n",
       "              'metadata': {'channel_id': 'UCv83tO5cePwHMt1952IVVHw',\n",
       "                           'end': 900.72,\n",
       "                           'published': datetime.datetime(2021, 10, 20, 17, 6, 20, tzinfo=tzlocal()),\n",
       "                           'start': 737.28,\n",
       "                           'text': \"were actually more accurate. So we can't \"\n",
       "                                   \"really do that. We can't use this what is \"\n",
       "                                   'called a mean pooling approach. Or we '\n",
       "                                   \"can't use it in its current form. Now the \"\n",
       "                                   'solution to this problem was introduced by '\n",
       "                                   'two people in 2019 Nils Reimers and Irenia '\n",
       "                                   'Gurevich. They introduced what is the '\n",
       "                                   'first sentence transformer or sentence '\n",
       "                                   'BERT. And it was found that sentence BERT '\n",
       "                                   'or S BERT outformed all of the previous '\n",
       "                                   'Save the Art models on pretty much all '\n",
       "                                   'benchmarks. Not all of them but most of '\n",
       "                                   'them. And it did it in a very quick time. '\n",
       "                                   'So if we compare it to BERT, if we wanted '\n",
       "                                   'to find the most similar sentence pair '\n",
       "                                   'from 10,000 sentences in that 2019 paper '\n",
       "                                   'they found that with BERT that took 65 '\n",
       "                                   'hours. With S BERT embeddings they could '\n",
       "                                   'create all the embeddings in just around '\n",
       "                                   'five seconds. And then they could compare '\n",
       "                                   'all those with cosine similarity in 0.01 '\n",
       "                                   \"seconds. So it's a lot faster. We go from \"\n",
       "                                   '65 hours to just over five seconds which '\n",
       "                                   'is I think pretty incredible. Now I think '\n",
       "                                   \"that's pretty much all the context we need \"\n",
       "                                   'behind sentence transformers. And what we '\n",
       "                                   'do now is dive into a little bit of how '\n",
       "                                   'they actually work. Now we said before we '\n",
       "                                   'have the core transform models and what S '\n",
       "                                   'BERT does is fine tunes on sentence pairs '\n",
       "                                   'using what is called a Siamese '\n",
       "                                   'architecture or Siamese network. What we '\n",
       "                                   'mean by a Siamese network is that we have '\n",
       "                                   'what we can see, what can view as two BERT '\n",
       "                                   'models that are identical and the weights '\n",
       "                                   'between those two models are tied. Now in '\n",
       "                                   'reality when implementing this we just use '\n",
       "                                   'a single BERT model. And what we do is we '\n",
       "                                   'process one sentence, a sentence A through '\n",
       "                                   'the model and then we process another '\n",
       "                                   'sentence, sentence B through the model. '\n",
       "                                   \"And that's the sentence pair. So with our \"\n",
       "                                   'cross-linked we were processing the '\n",
       "                                   'sentence pair together. We were putting '\n",
       "                                   'them both together, processing them all at '\n",
       "                                   'once. This time we process them '\n",
       "                                   'separately. And during training what '\n",
       "                                   'happens is the weights',\n",
       "                           'title': 'Intro to Sentence Embeddings with '\n",
       "                                    'Transformers',\n",
       "                           'url': 'https://youtu.be/WS1uVMGhlWQ'},\n",
       "              'score': 0.858609319,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsdoBYvk2JhY",
    "outputId": "42ef93f9-49ba-41b0-b825-73124338fefe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.027743928134441376,\n",
       " -0.02156776748597622,\n",
       " 0.03326483070850372,\n",
       " -0.0022080123890191317,\n",
       " -0.0020773091819137335,\n",
       " 0.02384025976061821,\n",
       " 0.01798475719988346,\n",
       " -0.006988263223320246,\n",
       " -0.007193902973085642,\n",
       " -0.03923186659812927,\n",
       " 0.012826338410377502,\n",
       " 0.05420522391796112,\n",
       " 0.002160959178581834,\n",
       " 0.01783139817416668,\n",
       " 0.009264240972697735,\n",
       " 0.018179940059781075,\n",
       " 0.014053205959498882,\n",
       " 0.0035551264882087708,\n",
       " 0.01659058965742588,\n",
       " -0.02186054177582264,\n",
       " -0.019127974286675453,\n",
       " -0.0031769585330039263,\n",
       " -0.00904814526438713,\n",
       " -0.028008820489048958,\n",
       " -0.007953723892569542,\n",
       " -0.012847251258790493,\n",
       " 0.028106411918997765,\n",
       " -0.02332441881299019,\n",
       " -0.023449892178177834,\n",
       " -0.01940680854022503,\n",
       " 0.026684360578656197,\n",
       " 0.009584899991750717,\n",
       " -0.018375124782323837,\n",
       " -0.010644466616213322,\n",
       " 0.011202134191989899,\n",
       " 0.0013671552296727896,\n",
       " 0.015363723039627075,\n",
       " 0.018444832414388657,\n",
       " 0.025387786328792572,\n",
       " -0.01889096572995186,\n",
       " 0.017008841037750244,\n",
       " 0.011278812773525715,\n",
       " 0.006231927778571844,\n",
       " -0.037196382880210876,\n",
       " 0.007695802953094244,\n",
       " 0.011090599931776524,\n",
       " -0.0014272787375375628,\n",
       " -0.017705924808979034,\n",
       " -0.018877023831009865,\n",
       " 0.019141916185617447,\n",
       " 0.0032013566233217716,\n",
       " 0.019797174260020256,\n",
       " -0.037196382880210876,\n",
       " -0.007514561526477337,\n",
       " -0.019504399970173836,\n",
       " 0.003966405987739563,\n",
       " 0.0015588531969115138,\n",
       " 0.025318076834082603,\n",
       " -0.009243329055607319,\n",
       " -0.0051932730711996555,\n",
       " -0.002072080969810486,\n",
       " 0.00033568934304639697,\n",
       " -0.003576038870960474,\n",
       " 0.013767401687800884,\n",
       " -0.009675520472228527,\n",
       " -0.016325699165463448,\n",
       " -0.011878305114805698,\n",
       " 0.0055940961465239525,\n",
       " 0.002924265805631876,\n",
       " 0.01985294185578823,\n",
       " -0.008999349549412727,\n",
       " 0.02226485125720501,\n",
       " -0.010226217098534107,\n",
       " -0.005987948272377253,\n",
       " 0.0263358186930418,\n",
       " -0.013906817883253098,\n",
       " -0.0015335839707404375,\n",
       " -0.016214165836572647,\n",
       " -0.015238247811794281,\n",
       " 0.00994041282683611,\n",
       " 0.0061029670760035515,\n",
       " -0.004726226907223463,\n",
       " -0.010295924730598927,\n",
       " 0.007793394848704338,\n",
       " 0.0130563760176301,\n",
       " 0.0029434356838464737,\n",
       " 0.026447352021932602,\n",
       " 0.015726206824183464,\n",
       " -0.003868814092129469,\n",
       " 0.01543343160301447,\n",
       " 0.016325699165463448,\n",
       " 0.027479035779833794,\n",
       " 0.01868184097111225,\n",
       " 0.018486658111214638,\n",
       " -0.008176790550351143,\n",
       " 0.009752199985086918,\n",
       " -0.00019071772112511098,\n",
       " 0.016451172530651093,\n",
       " 0.005318747833371162,\n",
       " -0.006287694443017244,\n",
       " -0.0062005589716136456,\n",
       " 0.009731287136673927,\n",
       " -0.038729965686798096,\n",
       " -0.007319378200918436,\n",
       " -0.009717345237731934,\n",
       " 0.011690092273056507,\n",
       " 0.0031665023416280746,\n",
       " -0.009076029062271118,\n",
       " -0.010658408515155315,\n",
       " -0.002842358546331525,\n",
       " -0.00447876239195466,\n",
       " 0.030894745141267776,\n",
       " 0.008581099100410938,\n",
       " -0.019978417083621025,\n",
       " 0.0029626053292304277,\n",
       " -0.023380184546113014,\n",
       " 0.02523442730307579,\n",
       " -0.023979676887392998,\n",
       " -0.011578558944165707,\n",
       " -0.013913788832724094,\n",
       " 0.03446381539106369,\n",
       " -0.024411868304014206,\n",
       " 0.025262311100959778,\n",
       " -0.025917569175362587,\n",
       " 0.04057026654481888,\n",
       " 0.005886871367692947,\n",
       " -0.018612133339047432,\n",
       " -0.01958804950118065,\n",
       " -0.027367502450942993,\n",
       " -0.01567043922841549,\n",
       " 0.0023770551197230816,\n",
       " 0.04729015380144119,\n",
       " 0.025206543505191803,\n",
       " 0.0002838437503669411,\n",
       " -0.008344090543687344,\n",
       " 0.014722405932843685,\n",
       " -0.0011048775631934404,\n",
       " -0.03900879994034767,\n",
       " -0.013767401687800884,\n",
       " -0.007172990590333939,\n",
       " 0.015043064951896667,\n",
       " -0.005367544014006853,\n",
       " 0.017231907695531845,\n",
       " -0.02548537775874138,\n",
       " -0.001527484506368637,\n",
       " 0.020494258031249046,\n",
       " 0.00803737435489893,\n",
       " 0.0050608268938958645,\n",
       " 0.008950553834438324,\n",
       " -0.03050437942147255,\n",
       " 0.02501136064529419,\n",
       " -0.012923930771648884,\n",
       " -0.005221156403422356,\n",
       " -0.0030619397293776274,\n",
       " 0.03159182891249657,\n",
       " 0.002514729043468833,\n",
       " -0.012331409379839897,\n",
       " 0.0065316734835505486,\n",
       " -0.009083000011742115,\n",
       " -0.012693893164396286,\n",
       " -0.011878305114805698,\n",
       " 0.014387805946171284,\n",
       " 0.007019632030278444,\n",
       " -0.0065769837237894535,\n",
       " 0.010755999945104122,\n",
       " 0.017008841037750244,\n",
       " 0.02066155895590782,\n",
       " -0.0016808428335934877,\n",
       " 0.00904814526438713,\n",
       " -0.04146253317594528,\n",
       " -0.009326978586614132,\n",
       " 0.01868184097111225,\n",
       " -0.0137325469404459,\n",
       " 0.013342180289328098,\n",
       " 0.006406198255717754,\n",
       " -0.004858672618865967,\n",
       " 0.02665647678077221,\n",
       " -0.0244258102029562,\n",
       " -0.020773092284798622,\n",
       " -0.027186261489987373,\n",
       " 0.004196443594992161,\n",
       " 0.012045605108141899,\n",
       " 0.015001239255070686,\n",
       " 0.0023073467891663313,\n",
       " -0.01962987519800663,\n",
       " -0.021261051297187805,\n",
       " -0.02874772809445858,\n",
       " 0.00963369570672512,\n",
       " 0.005479077342897654,\n",
       " -0.019030382856726646,\n",
       " -0.0006042843451723456,\n",
       " -0.01252659223973751,\n",
       " 0.008190732449293137,\n",
       " -0.009361833333969116,\n",
       " -0.6259253025054932,\n",
       " -0.025610852986574173,\n",
       " 0.0004152004257775843,\n",
       " -0.03794923052191734,\n",
       " 0.03326483070850372,\n",
       " 0.024091210216283798,\n",
       " -0.0051584187895059586,\n",
       " 0.012282613664865494,\n",
       " -0.027409328147768974,\n",
       " 0.03655506670475006,\n",
       " 0.006956894416362047,\n",
       " -0.005503475200384855,\n",
       " -0.011432171799242496,\n",
       " 0.019713524729013443,\n",
       " 0.01005194615572691,\n",
       " -0.029416928067803383,\n",
       " 0.013153967447578907,\n",
       " -0.0038095619529485703,\n",
       " 0.026642536744475365,\n",
       " 0.013160938397049904,\n",
       " -0.039901066571474075,\n",
       " 0.027813635766506195,\n",
       " -0.016967015340924263,\n",
       " 0.020229367539286613,\n",
       " -0.01702278107404709,\n",
       " -0.012596300803124905,\n",
       " 0.010546875186264515,\n",
       " -0.014241418801248074,\n",
       " 0.009570958092808723,\n",
       " 0.004900497850030661,\n",
       " -0.02361719310283661,\n",
       " 0.0122129051014781,\n",
       " 0.023282593116164207,\n",
       " -0.009452453814446926,\n",
       " 0.03655506670475006,\n",
       " 0.010316837579011917,\n",
       " 0.0030880803242325783,\n",
       " 0.023868143558502197,\n",
       " 0.00540936877951026,\n",
       " 0.009745229035615921,\n",
       " -0.02674012817442417,\n",
       " -0.007612152956426144,\n",
       " 0.00048752286238595843,\n",
       " 0.012240787968039513,\n",
       " 0.005653348285704851,\n",
       " 0.006549100391566753,\n",
       " 0.009083000011742115,\n",
       " -0.01027501281350851,\n",
       " 0.013160938397049904,\n",
       " -0.00038905980181880295,\n",
       " -0.004050055984407663,\n",
       " -0.007416969630867243,\n",
       " -0.011411258950829506,\n",
       " -0.006779137998819351,\n",
       " 0.022209083661437035,\n",
       " 0.007103282026946545,\n",
       " 0.03025342896580696,\n",
       " -0.01437386404722929,\n",
       " 0.0032797784078866243,\n",
       " -0.0035045878030359745,\n",
       " 0.02266915887594223,\n",
       " 0.015419489704072475,\n",
       " -0.014750289730727673,\n",
       " -0.019546223804354668,\n",
       " 0.013962584547698498,\n",
       " -0.016172340139746666,\n",
       " -0.015377664938569069,\n",
       " 0.0010369118535891175,\n",
       " 0.00018483608437236398,\n",
       " -0.04204808548092842,\n",
       " 0.021149516105651855,\n",
       " 0.004618179053068161,\n",
       " -0.006841875612735748,\n",
       " -0.00375379528850317,\n",
       " -0.015043064951896667,\n",
       " 0.025987276807427406,\n",
       " 0.0061761606484651566,\n",
       " 0.012310496531426907,\n",
       " -0.0036806014832109213,\n",
       " 0.011439141817390919,\n",
       " 0.02512289397418499,\n",
       " -0.01366283930838108,\n",
       " -0.03694543242454529,\n",
       " -0.006692002527415752,\n",
       " 0.02717231959104538,\n",
       " -0.00685930298641324,\n",
       " -0.020522141829133034,\n",
       " 0.01431809738278389,\n",
       " -0.014569047838449478,\n",
       " -0.014596930705010891,\n",
       " -0.0013444999931380153,\n",
       " 0.03449169918894768,\n",
       " -0.033236946910619736,\n",
       " -0.038172297179698944,\n",
       " -0.0009297352517023683,\n",
       " 0.010010120458900928,\n",
       " 0.0004152004257775843,\n",
       " -0.0043985978700220585,\n",
       " 0.026391586288809776,\n",
       " -0.050775572657585144,\n",
       " 0.018946733325719833,\n",
       " 0.005527873057872057,\n",
       " 0.012861193157732487,\n",
       " -0.008378945291042328,\n",
       " -0.003041027346625924,\n",
       " 0.005496504250913858,\n",
       " -0.0040883952751755714,\n",
       " -0.007207844406366348,\n",
       " -0.008169819600880146,\n",
       " 0.018793374300003052,\n",
       " -0.0025600395165383816,\n",
       " -0.011690092273056507,\n",
       " 0.006479392293840647,\n",
       " 0.011334579437971115,\n",
       " -0.009696433320641518,\n",
       " -0.03797711431980133,\n",
       " 0.00941062904894352,\n",
       " 0.0116482675075531,\n",
       " 0.0025460978504270315,\n",
       " -0.0050852252170443535,\n",
       " 0.005615008529275656,\n",
       " 0.010442312806844711,\n",
       " 0.012791484594345093,\n",
       " -0.01179465465247631,\n",
       " -0.010735088028013706,\n",
       " -0.011348521336913109,\n",
       " -0.0060332585126161575,\n",
       " 0.006963865365833044,\n",
       " 0.03036496229469776,\n",
       " 0.007674890570342541,\n",
       " -0.009905558079481125,\n",
       " -0.0025269282050430775,\n",
       " -0.00030802382389083505,\n",
       " -0.013906817883253098,\n",
       " -0.0016294330125674605,\n",
       " 0.015098831616342068,\n",
       " 0.010602641850709915,\n",
       " 0.006026288028806448,\n",
       " 0.008504420518875122,\n",
       " -0.003312889952212572,\n",
       " -0.026907427236437798,\n",
       " 0.0011292754206806421,\n",
       " 0.0014769459376111627,\n",
       " 0.012554476037621498,\n",
       " -0.030337078496813774,\n",
       " -0.017413148656487465,\n",
       " -0.020089950412511826,\n",
       " 0.004903983324766159,\n",
       " -0.003732882672920823,\n",
       " -0.014861823059618473,\n",
       " 0.001255621900781989,\n",
       " -0.006430596578866243,\n",
       " -0.021553825587034225,\n",
       " -0.013356122188270092,\n",
       " -0.02149805799126625,\n",
       " -0.026029102504253387,\n",
       " -0.010602641850709915,\n",
       " -0.03468688204884529,\n",
       " -0.017092490568757057,\n",
       " -0.0429961159825325,\n",
       " 0.02570844441652298,\n",
       " 0.026795893907546997,\n",
       " -0.013690722174942493,\n",
       " 0.006085540167987347,\n",
       " -0.01554496493190527,\n",
       " -0.010937241837382317,\n",
       " 0.02911021187901497,\n",
       " 0.01571226492524147,\n",
       " 0.01028895378112793,\n",
       " -0.024216685444116592,\n",
       " 0.010498079471290112,\n",
       " -0.057662755250930786,\n",
       " -0.0023352301213890314,\n",
       " 0.006371344439685345,\n",
       " 0.0062110149301588535,\n",
       " 0.01095118373632431,\n",
       " -0.017901107668876648,\n",
       " 0.0043637435883283615,\n",
       " 0.0020494258496910334,\n",
       " -0.01783139817416668,\n",
       " -0.029361162334680557,\n",
       " 0.02710261195898056,\n",
       " -0.006270267069339752,\n",
       " 0.007730657234787941,\n",
       " 0.013614042662084103,\n",
       " -0.004670460242778063,\n",
       " -0.007291494868695736,\n",
       " -0.013091230764985085,\n",
       " -0.042354799807071686,\n",
       " 0.036527182906866074,\n",
       " -0.006001890171319246,\n",
       " 0.006221471354365349,\n",
       " 0.0009689462604001164,\n",
       " 0.011717976070940495,\n",
       " -0.002793562598526478,\n",
       " 0.029946712777018547,\n",
       " 0.015224305912852287,\n",
       " 0.021414408460259438,\n",
       " -0.005778823047876358,\n",
       " 0.018542423844337463,\n",
       " 0.03120146319270134,\n",
       " 0.011453083716332912,\n",
       " 0.023714784532785416,\n",
       " -0.010846621356904507,\n",
       " -0.0015318412333726883,\n",
       " -0.01411594357341528,\n",
       " 0.014053205959498882,\n",
       " -0.01567043922841549,\n",
       " 0.022850401699543,\n",
       " 0.020591849461197853,\n",
       " 0.009682491421699524,\n",
       " -0.026684360578656197,\n",
       " -0.03189854696393013,\n",
       " -0.03504936397075653,\n",
       " 0.0024258510675281286,\n",
       " 0.014046235010027885,\n",
       " -0.008476536720991135,\n",
       " 0.03658294677734375,\n",
       " -0.0113136675208807,\n",
       " 0.036387763917446136,\n",
       " 0.006343461107462645,\n",
       " 0.0013418860035017133,\n",
       " 0.03541184961795807,\n",
       " 0.013174880295991898,\n",
       " 0.014833939261734486,\n",
       " -0.0033947972115129232,\n",
       " 0.0049179247580468655,\n",
       " -0.007026602979749441,\n",
       " 0.03295811265707016,\n",
       " -0.022613393142819405,\n",
       " 0.00812799483537674,\n",
       " 0.009236358106136322,\n",
       " 0.01659058965742588,\n",
       " 0.002291662385687232,\n",
       " 0.007361202966421843,\n",
       " -0.010539904236793518,\n",
       " 0.012589329853653908,\n",
       " 0.011299725621938705,\n",
       " 0.02874772809445858,\n",
       " 0.0033059190027415752,\n",
       " 0.008134965784847736,\n",
       " 0.000656129966955632,\n",
       " -0.00481684785336256,\n",
       " -0.006657148711383343,\n",
       " 0.04544985294342041,\n",
       " -0.00873445812612772,\n",
       " 0.04441816732287407,\n",
       " 0.00680353632196784,\n",
       " -0.010400488041341305,\n",
       " -0.006855817511677742,\n",
       " -0.012122283689677715,\n",
       " 0.004639091435819864,\n",
       " -0.004489218350499868,\n",
       " 0.010965125635266304,\n",
       " -0.0009401915594935417,\n",
       " -0.0128333093598485,\n",
       " 0.006238898262381554,\n",
       " -0.008141936734318733,\n",
       " 0.009145736694335938,\n",
       " 0.02145623415708542,\n",
       " 0.020006299018859863,\n",
       " 0.0010369118535891175,\n",
       " 0.01596321538090706,\n",
       " -0.006186617072671652,\n",
       " 0.035467613488435745,\n",
       " 0.00619010254740715,\n",
       " 0.003156046150252223,\n",
       " -0.018068406730890274,\n",
       " -0.0036004369612783194,\n",
       " -0.003583009820431471,\n",
       " 0.0035603547003120184,\n",
       " -0.012024692259728909,\n",
       " 0.010553846135735512,\n",
       " -0.025108952075242996,\n",
       " 0.02336624264717102,\n",
       " 0.006514246575534344,\n",
       " -0.0045171016827225685,\n",
       " 0.018667899072170258,\n",
       " 0.013927730731666088,\n",
       " 0.024858001619577408,\n",
       " -0.00890175811946392,\n",
       " -0.029639994725584984,\n",
       " 0.025555085390806198,\n",
       " -0.008169819600880146,\n",
       " -0.020954333245754242,\n",
       " -0.016897307708859444,\n",
       " -0.02674012817442417,\n",
       " -0.017524681985378265,\n",
       " -0.03761463239789009,\n",
       " 0.040849100798368454,\n",
       " 0.024160917848348618,\n",
       " 0.010240158066153526,\n",
       " 0.00045615408453159034,\n",
       " 0.0021783863194286823,\n",
       " -0.020159658044576645,\n",
       " 0.010532933287322521,\n",
       " 0.023645076900720596,\n",
       " -0.002216725843027234,\n",
       " 0.013885905966162682,\n",
       " 0.00378167862072587,\n",
       " -0.015740148723125458,\n",
       " 0.0022742352448403835,\n",
       " -0.032651398330926895,\n",
       " -0.023449892178177834,\n",
       " 0.02728385291993618,\n",
       " -0.009264240972697735,\n",
       " -0.014778172597289085,\n",
       " -0.03783769905567169,\n",
       " -0.006678061094135046,\n",
       " -0.026196401566267014,\n",
       " 0.00014148619084153324,\n",
       " 0.015517081134021282,\n",
       " -0.0067094299010932446,\n",
       " 0.008999349549412727,\n",
       " 0.003802591236308217,\n",
       " -0.0018943247850984335,\n",
       " -0.006730342283844948,\n",
       " 2.6463990252523217e-06,\n",
       " 0.0312851145863533,\n",
       " 0.03284658119082451,\n",
       " -0.011160308495163918,\n",
       " -0.03153606131672859,\n",
       " 0.005304806400090456,\n",
       " 0.011731917038559914,\n",
       " 0.042466334998607635,\n",
       " 0.051361121237277985,\n",
       " -0.01717614009976387,\n",
       " 0.00043611295404843986,\n",
       " -0.028942912817001343,\n",
       " -0.02791122905910015,\n",
       " -0.0015597245655953884,\n",
       " -0.03156394511461258,\n",
       " 0.021470176056027412,\n",
       " -0.016242047771811485,\n",
       " -0.018486658111214638,\n",
       " -0.010149537585675716,\n",
       " -0.002795305335894227,\n",
       " -0.004391626920551062,\n",
       " 0.005175845697522163,\n",
       " 0.01739920675754547,\n",
       " -0.007437882013618946,\n",
       " -0.043637435883283615,\n",
       " 0.0021452747751027346,\n",
       " -0.0026889999862760305,\n",
       " -0.0017967330059036613,\n",
       " -0.020076008513569832,\n",
       " 0.017036722972989082,\n",
       " 0.03139664605259895,\n",
       " 0.03588586300611496,\n",
       " 0.00252169999293983,\n",
       " 0.036861781030893326,\n",
       " 0.024160917848348618,\n",
       " 0.019574107602238655,\n",
       " -0.03530031442642212,\n",
       " -0.0008247370715253055,\n",
       " 0.011174250394105911,\n",
       " -0.002113905968144536,\n",
       " 0.0070022051222622395,\n",
       " -0.011641296558082104,\n",
       " 0.02816217765212059,\n",
       " 0.0026959709357470274,\n",
       " 0.0053082918748259544,\n",
       " 0.01765015721321106,\n",
       " 0.0038444162346422672,\n",
       " 0.003304176265373826,\n",
       " 0.010121653787791729,\n",
       " 0.014806056395173073,\n",
       " -0.00759124057367444,\n",
       " -0.002357885241508484,\n",
       " -0.017204023897647858,\n",
       " 0.002427593804895878,\n",
       " 0.005499989725649357,\n",
       " 0.0128333093598485,\n",
       " -0.02127499133348465,\n",
       " -0.020340900868177414,\n",
       " 0.016604531556367874,\n",
       " -0.01247082557529211,\n",
       " -0.006047200411558151,\n",
       " -0.011641296558082104,\n",
       " -0.005168875213712454,\n",
       " -0.020745208486914635,\n",
       " -0.002692485461011529,\n",
       " -0.02449551783502102,\n",
       " 0.006625779904425144,\n",
       " -0.011655238457024097,\n",
       " -0.013669809326529503,\n",
       " 0.034882064908742905,\n",
       " -0.00216967286542058,\n",
       " 0.006040229462087154,\n",
       " -0.012840280309319496,\n",
       " -0.00798160769045353,\n",
       " -0.005311777349561453,\n",
       " -0.020201483741402626,\n",
       " -0.014248388819396496,\n",
       " -0.01947651617228985,\n",
       " -0.007800365798175335,\n",
       " -0.02109375037252903,\n",
       " 0.005869443994015455,\n",
       " 0.02354748547077179,\n",
       " 0.01666029915213585,\n",
       " 0.02406332641839981,\n",
       " -0.0029800324700772762,\n",
       " -0.010804795660078526,\n",
       " 0.0025269282050430775,\n",
       " -0.014764230698347092,\n",
       " -0.018291473388671875,\n",
       " -0.002570495940744877,\n",
       " -0.005283894017338753,\n",
       " -0.027855461463332176,\n",
       " 0.02226485125720501,\n",
       " -0.04943716898560524,\n",
       " -0.00549301877617836,\n",
       " -0.006263296119868755,\n",
       " 0.03741944953799248,\n",
       " -0.005587125197052956,\n",
       " 0.028482837602496147,\n",
       " -0.016018981114029884,\n",
       " -0.014861823059618473,\n",
       " 0.017998699098825455,\n",
       " 0.03555126488208771,\n",
       " -0.00574048375710845,\n",
       " 0.018291473388671875,\n",
       " -0.0016416319413110614,\n",
       " -0.01684154011309147,\n",
       " -0.004555441439151764,\n",
       " -0.02852466143667698,\n",
       " 0.005677746143192053,\n",
       " -0.046453651040792465,\n",
       " -0.014290214516222477,\n",
       " 0.005329204257577658,\n",
       " 0.023784494027495384,\n",
       " 0.03518878296017647,\n",
       " 0.0022533228620886803,\n",
       " -0.00012939615407958627,\n",
       " 0.0037991057615727186,\n",
       " 0.0011327608954161406,\n",
       " -0.0006949052331037819,\n",
       " 0.014499339275062084,\n",
       " 0.02662859484553337,\n",
       " 0.017482856288552284,\n",
       " 0.01252659223973751,\n",
       " 0.0048377602361142635,\n",
       " 0.01670212298631668,\n",
       " -0.013126084581017494,\n",
       " -0.009849791415035725,\n",
       " -0.018082348629832268,\n",
       " 0.021010100841522217,\n",
       " 0.023087410256266594,\n",
       " -0.02908232808113098,\n",
       " 0.02057790756225586,\n",
       " -0.006514246575534344,\n",
       " -0.02343595214188099,\n",
       " -0.01911403238773346,\n",
       " 0.0315081812441349,\n",
       " -0.03226102888584137,\n",
       " 0.04511525109410286,\n",
       " 0.028357362374663353,\n",
       " 0.009180591441690922,\n",
       " -0.05060826987028122,\n",
       " 0.008232557214796543,\n",
       " -0.011892247013747692,\n",
       " -0.009271211922168732,\n",
       " 0.009152707643806934,\n",
       " -0.007842190563678741,\n",
       " 0.01794293150305748,\n",
       " -0.0005899069947190583,\n",
       " -0.006935982033610344,\n",
       " -0.017664099112153053,\n",
       " 0.004527558106929064,\n",
       " -0.014415688812732697,\n",
       " -0.046453651040792465,\n",
       " 0.03560703247785568,\n",
       " 0.007695802953094244,\n",
       " -0.00039319871575571597,\n",
       " 0.01224775891751051,\n",
       " 0.012700863182544708,\n",
       " -0.00972431618720293,\n",
       " -0.004736683331429958,\n",
       " -0.014345981180667877,\n",
       " -0.03343212977051735,\n",
       " 0.013509480282664299,\n",
       " 0.033013880252838135,\n",
       " 0.01618628203868866,\n",
       " 0.010281983762979507,\n",
       " 0.053006239235401154,\n",
       " -0.009124824777245522,\n",
       " -0.003548155538737774,\n",
       " 0.03014189563691616,\n",
       " -0.008685661479830742,\n",
       " -0.01078388374298811,\n",
       " -0.03390614688396454,\n",
       " 0.022794634103775024,\n",
       " 0.003203099127858877,\n",
       " 0.021846599876880646,\n",
       " 0.029890945181250572,\n",
       " -0.014666639268398285,\n",
       " 0.014499339275062084,\n",
       " -0.0030427700839936733,\n",
       " 0.016799714416265488,\n",
       " 0.022320616990327835,\n",
       " -0.00470531452447176,\n",
       " -0.035467613488435745,\n",
       " 0.0033703993540257215,\n",
       " -0.022878283634781837,\n",
       " 0.005221156403422356,\n",
       " 0.01512671448290348,\n",
       " 0.0025426126085221767,\n",
       " 0.014931530691683292,\n",
       " -0.027032902464270592,\n",
       " -0.008016461506485939,\n",
       " 0.018430890515446663,\n",
       " 0.0036143786273896694,\n",
       " 0.015280072577297688,\n",
       " -0.0028197031933814287,\n",
       " 0.033125415444374084,\n",
       " 0.007409998681396246,\n",
       " 0.00048534446978010237,\n",
       " -0.017970815300941467,\n",
       " 0.027841519564390182,\n",
       " -0.014220505952835083,\n",
       " 0.0037293974310159683,\n",
       " -0.029277512803673744,\n",
       " 0.01371860597282648,\n",
       " 0.01769198291003704,\n",
       " -0.0007419583853334188,\n",
       " -0.0025199572555720806,\n",
       " -0.0032187835313379765,\n",
       " 0.004018687177449465,\n",
       " -0.0024502489250153303,\n",
       " 0.0032815211452543736,\n",
       " -0.03134087845683098,\n",
       " -0.006873244419693947,\n",
       " 0.01078388374298811,\n",
       " -1.7862766981124878e-05,\n",
       " -0.007305436301976442,\n",
       " -0.04031931608915329,\n",
       " -0.004011716227978468,\n",
       " 0.010400488041341305,\n",
       " 0.002912066876888275,\n",
       " -0.007709744852036238,\n",
       " -0.005266466643661261,\n",
       " 0.005987948272377253,\n",
       " -0.013600101694464684,\n",
       " -0.039343398064374924,\n",
       " 0.0017845340771600604,\n",
       " -0.009975266642868519,\n",
       " 0.019643817096948624,\n",
       " 0.019546223804354668,\n",
       " 0.013467655517160892,\n",
       " 0.018138116225600243,\n",
       " 0.01852848194539547,\n",
       " 0.003502845298498869,\n",
       " -0.026503119617700577,\n",
       " 0.0218326598405838,\n",
       " -0.008832049556076527,\n",
       " -0.005067797843366861,\n",
       " 0.027269911020994186,\n",
       " -0.012958784587681293,\n",
       " -0.02534596063196659,\n",
       " 0.030086129903793335,\n",
       " -0.005249039735645056,\n",
       " -0.029249629005789757,\n",
       " -0.029639994725584984,\n",
       " 0.022418208420276642,\n",
       " -0.005364058539271355,\n",
       " 0.016576647758483887,\n",
       " -0.011961954645812511,\n",
       " -0.012603271752595901,\n",
       " -0.03702908009290695,\n",
       " 0.011836479417979717,\n",
       " 0.0030898230616003275,\n",
       " 0.017413148656487465,\n",
       " -0.0026750583201646805,\n",
       " 0.004032628610730171,\n",
       " -0.018375124782323837,\n",
       " 0.02863619476556778,\n",
       " -0.02358930930495262,\n",
       " 0.010191362351179123,\n",
       " -0.004862158093601465,\n",
       " 0.006437567062675953,\n",
       " 0.025903627276420593,\n",
       " -0.00406399741768837,\n",
       " 0.022069666534662247,\n",
       " 0.0037921348121017218,\n",
       " 0.030560145154595375,\n",
       " 0.04302399978041649,\n",
       " 0.003053226275369525,\n",
       " 0.00862292479723692,\n",
       " 0.0016459886683151126,\n",
       " -0.0027011989150196314,\n",
       " -0.017566507682204247,\n",
       " -0.00871354527771473,\n",
       " -0.02163747511804104,\n",
       " 0.03228891268372536,\n",
       " -0.021735066547989845,\n",
       " -0.001689556404016912,\n",
       " -0.003210070077329874,\n",
       " -0.012108342722058296,\n",
       " -0.0018403007416054606,\n",
       " 0.0021783863194286823,\n",
       " -0.0009541332256048918,\n",
       " 0.002467676065862179,\n",
       " -0.0033947972115129232,\n",
       " -0.004060511942952871,\n",
       " 0.03485418111085892,\n",
       " 0.009605811908841133,\n",
       " -0.008002519607543945,\n",
       " -0.003691057674586773,\n",
       " -0.0056394063867628574,\n",
       " -0.0022271822672337294,\n",
       " -0.02102404274046421,\n",
       " 0.0038269890937954187,\n",
       " 0.008100111968815327,\n",
       " -0.045979633927345276,\n",
       " -0.022836459800601006,\n",
       " 0.015057005919516087,\n",
       " 0.006660634186118841,\n",
       " 0.020926449447870255,\n",
       " -0.023282593116164207,\n",
       " 0.005364058539271355,\n",
       " 0.00270468438975513,\n",
       " 0.02647523581981659,\n",
       " -0.005893841851502657,\n",
       " -0.01666029915213585,\n",
       " 0.013425830751657486,\n",
       " -0.003121191868558526,\n",
       " -0.029863061383366585,\n",
       " 0.00481684785336256,\n",
       " -0.0122686717659235,\n",
       " -0.0006844489835202694,\n",
       " 0.015698323026299477,\n",
       " 3.3982825698331e-05,\n",
       " -0.005468620918691158,\n",
       " -0.014680581167340279,\n",
       " 0.01596321538090706,\n",
       " -0.019127974286675453,\n",
       " 0.024481575936079025,\n",
       " -0.00417553074657917,\n",
       " -0.005984462797641754,\n",
       " -0.0138998469337821,\n",
       " 0.007884015329182148,\n",
       " -0.029612112790346146,\n",
       " -0.0056289504282176495,\n",
       " -0.004670460242778063,\n",
       " 0.004865643568336964,\n",
       " 0.009271211922168732,\n",
       " 0.024844059720635414,\n",
       " -0.027423270046710968,\n",
       " -0.005587125197052956,\n",
       " -0.006521217059344053,\n",
       " 0.012254729866981506,\n",
       " 0.0024920739233493805,\n",
       " -0.015447372570633888,\n",
       " 0.014569047838449478,\n",
       " -0.007842190563678741,\n",
       " 0.0042940350249409676,\n",
       " -0.00186992681119591,\n",
       " -0.009459424763917923,\n",
       " 0.0029486636631190777,\n",
       " 0.021330758929252625,\n",
       " -0.01411594357341528,\n",
       " 0.008908729068934917,\n",
       " 0.012401117943227291,\n",
       " -0.015768030658364296,\n",
       " -0.00890175811946392,\n",
       " 0.018765490502119064,\n",
       " 0.03457534685730934,\n",
       " 0.0035011025611311197,\n",
       " -0.0312851145863533,\n",
       " -0.019100090488791466,\n",
       " -0.021944193169474602,\n",
       " -0.009787053801119328,\n",
       " -0.021442292258143425,\n",
       " -0.023240767419338226,\n",
       " -0.003563839942216873,\n",
       " 0.022404268383979797,\n",
       " 0.021302875131368637,\n",
       " -0.036053165793418884,\n",
       " -0.029974596574902534,\n",
       " -0.02823188714683056,\n",
       " -0.020452434197068214,\n",
       " 0.007911899127066135,\n",
       " 0.0038932119496166706,\n",
       " 0.0005737869651056826,\n",
       " 0.010247129015624523,\n",
       " 0.021010100841522217,\n",
       " -0.026837719604372978,\n",
       " 0.05967035889625549,\n",
       " 0.0031107356771826744,\n",
       " -0.005562727339565754,\n",
       " -0.001781048602424562,\n",
       " 0.020591849461197853,\n",
       " -0.024676760658621788,\n",
       " 0.0024938166607171297,\n",
       " -0.007291494868695736,\n",
       " -0.010769941844046116,\n",
       " -0.06574892997741699,\n",
       " 0.01684154011309147,\n",
       " 0.025569027289748192,\n",
       " -0.008218616247177124,\n",
       " 0.031229346990585327,\n",
       " 0.013948643580079079,\n",
       " -0.0046844021417200565,\n",
       " 0.011780712753534317,\n",
       " 0.0008748399559408426,\n",
       " 0.02365901879966259,\n",
       " 0.034658998250961304,\n",
       " 0.004360258113592863,\n",
       " 0.0075842696242034435,\n",
       " -0.023742668330669403,\n",
       " -0.012519622221589088,\n",
       " 0.00484473118558526,\n",
       " -0.004607722628861666,\n",
       " -0.009926470927894115,\n",
       " 0.004234782885760069,\n",
       " 0.013858022168278694,\n",
       " -0.0006151762790977955,\n",
       " -0.027074728161096573,\n",
       " -0.01028895378112793,\n",
       " 0.009431540966033936,\n",
       " 0.006695488002151251,\n",
       " -0.027492977678775787,\n",
       " 0.006538644433021545,\n",
       " -0.00619010254740715,\n",
       " -0.028217945247888565,\n",
       " -0.005848531611263752,\n",
       " 0.022515801712870598,\n",
       " -0.007486678194254637,\n",
       " -0.02676801010966301,\n",
       " 0.006904613226652145,\n",
       " -0.005440737586468458,\n",
       " -0.016604531556367874,\n",
       " 0.0373636819422245,\n",
       " 0.0070405444130301476,\n",
       " -0.0005045142606832087,\n",
       " -0.009675520472228527,\n",
       " -0.002938207471743226,\n",
       " 0.0038513869512826204,\n",
       " -0.0013924245722591877,\n",
       " 0.004687887150794268,\n",
       " 0.018221765756607056,\n",
       " -0.010024062357842922,\n",
       " 0.02219514176249504,\n",
       " 0.006730342283844948,\n",
       " -0.03596951439976692,\n",
       " 0.008309236727654934,\n",
       " -0.010811766609549522,\n",
       " 0.00941062904894352,\n",
       " -0.0022707500029355288,\n",
       " -0.020745208486914635,\n",
       " 0.008448653854429722,\n",
       " -0.036164697259664536,\n",
       " 0.030225545167922974,\n",
       " 0.002877212595194578,\n",
       " -0.04394415020942688,\n",
       " -0.02303164266049862,\n",
       " -0.003882755758240819,\n",
       " 0.028190061450004578,\n",
       " -0.012993638403713703,\n",
       " 0.018946733325719833,\n",
       " 0.2228436917066574,\n",
       " -0.028315536677837372,\n",
       " 0.011850421316921711,\n",
       " 0.0067094299010932446,\n",
       " 0.014694523066282272,\n",
       " 0.002096479060128331,\n",
       " 0.03415709733963013,\n",
       " 0.0054860482923686504,\n",
       " -0.02127499133348465,\n",
       " -0.005946123506873846,\n",
       " 0.011292754672467709,\n",
       " -0.0010491108987480402,\n",
       " -0.020020240917801857,\n",
       " 0.00619010254740715,\n",
       " 0.005573183763772249,\n",
       " -0.03131299465894699,\n",
       " -0.03800499811768532,\n",
       " -0.02911021187901497,\n",
       " -0.011669179424643517,\n",
       " -0.007918870076537132,\n",
       " 0.01897461526095867,\n",
       " 0.0071451072581112385,\n",
       " -0.0014054948696866632,\n",
       " -0.024439752101898193,\n",
       " 0.011927100829780102,\n",
       " -0.0076191239058971405,\n",
       " -0.009870704263448715,\n",
       " -0.02050819993019104,\n",
       " 0.0018873539520427585,\n",
       " 0.03504936397075653,\n",
       " -0.020006299018859863,\n",
       " 0.009814937599003315,\n",
       " 0.026029102504253387,\n",
       " 0.01560073159635067,\n",
       " -0.005618494004011154,\n",
       " -0.02208360843360424,\n",
       " 0.00613433588296175,\n",
       " -0.005698658525943756,\n",
       " 0.020424550399184227,\n",
       " -0.004628635011613369,\n",
       " 0.025067126378417015,\n",
       " -0.011432171799242496,\n",
       " 0.003704999340698123,\n",
       " -0.007974636740982533,\n",
       " -0.01106271706521511,\n",
       " 0.0128890760242939,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9sDCElt2nIU"
   },
   "outputs": [],
   "source": [
    "limit = 3750\n",
    "\n",
    "def retrieve(query):\n",
    "    res = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        engine=embed_model\n",
    "    )\n",
    "\n",
    "    # retrieve from Pinecone\n",
    "    xq = res['data'][0]['embedding']\n",
    "\n",
    "    # get relevant contexts\n",
    "    res = index.query(xq, top_k=3, include_metadata=True)\n",
    "    contexts = [\n",
    "        x['metadata']['text'] for x in res['matches']\n",
    "    ]\n",
    "\n",
    "    # build our prompt with the retrieved contexts included\n",
    "    prompt_start = (\n",
    "        \"Answer the question based on the context below.\\n\\n\"+\n",
    "        \"Context:\\n\"\n",
    "    )\n",
    "    prompt_end = (\n",
    "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    )\n",
    "    # append contexts until hitting limit\n",
    "    for i in range(1, len(contexts)):\n",
    "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
    "                prompt_end\n",
    "            )\n",
    "            break\n",
    "        elif i == len(contexts)-1:\n",
    "            prompt = (\n",
    "                prompt_start +\n",
    "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
    "                prompt_end\n",
    "            )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "9bmwaWVW2tT7",
    "outputId": "dc6eae18-18ba-4497-d766-f89408c7dece"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Answer the question based on the context below.\\n\\nContext:\\npairs of related sentences you can go ahead and actually try training or fine-tuning using NLI with multiple negative ranking loss. If you don't have that fine. Another option is that you have a semantic textual similarity data set or STS and what this is is you have so you have sentence A here, sentence B here and then you have a score from from 0 to 1 that tells you the similarity between those two scores and you would train this using something like cosine similarity loss. Now if that's not an option and your focus or use case is on building a sentence transformer for another language where there is no current sentence transformer you can use multilingual parallel data. So what I mean by that is so parallel data just means translation pairs so if you have for example a English sentence and then you have another language here so it can it can be anything I'm just going to put XX and that XX is your target language you can fine-tune a model using something called multilingual knowledge distillation and what that does is takes a monolingual model for example in English and using those translation pairs it distills the knowledge the semantic similarity knowledge from that monolingual English model into a multilingual model which can handle both English and your target language. So they're three options quite popular very common that you can go for and as a supervised methods the chances are that probably going to outperform anything you do with unsupervised training at least for now. So if none of those sound like something\\n\\n---\\n\\nwere actually more accurate. So we can't really do that. We can't use this what is called a mean pooling approach. Or we can't use it in its current form. Now the solution to this problem was introduced by two people in 2019 Nils Reimers and Irenia Gurevich. They introduced what is the first sentence transformer or sentence BERT. And it was found that sentence BERT or S BERT outformed all of the previous Save the Art models on pretty much all benchmarks. Not all of them but most of them. And it did it in a very quick time. So if we compare it to BERT, if we wanted to find the most similar sentence pair from 10,000 sentences in that 2019 paper they found that with BERT that took 65 hours. With S BERT embeddings they could create all the embeddings in just around five seconds. And then they could compare all those with cosine similarity in 0.01 seconds. So it's a lot faster. We go from 65 hours to just over five seconds which is I think pretty incredible. Now I think that's pretty much all the context we need behind sentence transformers. And what we do now is dive into a little bit of how they actually work. Now we said before we have the core transform models and what S BERT does is fine tunes on sentence pairs using what is called a Siamese architecture or Siamese network. What we mean by a Siamese network is that we have what we can see, what can view as two BERT models that are identical and the weights between those two models are tied. Now in reality when implementing this we just use a single BERT model. And what we do is we process one sentence, a sentence A through the model and then we process another sentence, sentence B through the model. And that's the sentence pair. So with our cross-linked we were processing the sentence pair together. We were putting them both together, processing them all at once. This time we process them separately. And during training what happens is the weights\\n\\n---\\n\\nTransformer-based Sequential Denoising Autoencoder. So what we'll do is jump straight into it and take a look at where we might want to use this training approach and and how we can actually implement it. So the first question we need to ask is do we really need to resort to unsupervised training? Now what we're going to do here is just have a look at a few of the most popular training approaches and what sort of data we need for that. So the first one we're looking at here is Natural Language Inference or NLI and NLI requires that we have pairs of sentences that are labeled as either contradictory, neutral which means they're not necessarily related or as entailing or as inferring each other. So you have pairs that entail each other so they are both very similar pairs that are neutral and also pairs that are contradictory. And this is the traditional NLI data. Now using another version of fine-tuning with NLI called a multiple negatives ranking loss you can get by with only entailment pairs so pairs that are related to each other or positive pairs and it can also use contradictory pairs to improve the performance of training as well but you don't need it. So if you have positive pairs of related sentences you can go ahead and actually try training or fine-tuning using NLI with multiple negative ranking loss. If you don't have that fine. Another option is that you have a semantic textual similarity data set or STS and what this is is you have so you have sentence A here, sentence B\\n\\nQuestion: Which training method should I use for sentence transformers when I only have pairs of related sentences?\\nAnswer:\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we retrieve relevant items from Pinecone\n",
    "query_with_contexts = retrieve(query)\n",
    "query_with_contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yDaZ9Vaz2v8P",
    "outputId": "775b663e-4680-48fb-b60d-70a3c37272ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Which training method should I use for sentence transformers when I only have pairs of related sentences?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8LN2pOh21Lc"
   },
   "outputs": [],
   "source": [
    "q = \"What first steps do you recommend in order to leverage sentence transformer as a product for e-commerce industry?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "UNx9WYR23PG_",
    "outputId": "1ad41b19-44ef-4741-cd56-d3de9980d2e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Answer the question based on the context below.\\n\\nContext:\\nI've already done this, so I'm not going to rerun it. But if you don't have Sentence Transformers, you will need to install it. Then after that, all you want to do is you want to write from Sentence Transformers. We want to import the Sentence Transformer object. And from there, we can just initialize our model super easy. We just write model, Sentence Transformer. And then in here, we just need to type our model name. Now, if you Google Sentence Transformers or Spert, you will find the web page for this library. And it has loads of different models on there. One of the highest performing ones that I found on there at the moment is called all mp-net base v2. Okay, so we just execute that. And usually, you will need to download the model. So you will see a load of loading bars or progress bars. That's fine. It's just downloading the model for you. I already have it downloaded, so I don't need to run it again. And then what we need is a set of sentences so that we can actually compare, we can compare these and look at what the Sentence Transformer believes is the most similar. Now, all of these are completely random, but we have this one here. The bees decided to have a mutiny against their queen. And I just rewrote that in a way that we don't have any matching words between the two sentences. So we have flying, singing insects, rebellion, opposition to the matriarch. Now, the meaning there is pretty much the same, maybe not exactly the same, but pretty much. But there are no shared words other than, I think, to and the. Yeah, to and the. So in terms of sparse vector encoding, this wouldn't score very well. But we'll see that with dense vectors, it will. So the first thing we want to do is encode our embeddings. So we write embeddings because model dot encode sentences. Okay, and then let's have a look at what the outputs or at least the shape of what outputs.\\n\\nQuestion: What first steps do you recommend in order to leverage sentence transformer as a product for e-commerce industry?\\nAnswer:\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we retrieve relevant items from Pinecone\n",
    "query_with_contexts = retrieve(q)\n",
    "query_with_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "bzmjfAjG3RXn",
    "outputId": "f8a87fc3-5226-4ef3-8fb6-915589522079"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'To leverage sentence transformer as a product for e-commerce industry, the first steps would be to install Sentence Transformers, import the Sentence Transformer object, and initialize the model. After that, you would need to download the model and encode the embeddings.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then we complete the context-infused query\n",
    "complete(query_with_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpgqPYdk3oeA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13e2ece863ab4aafa2856609e4c638b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c7b5d36c2444b1ba2a1ea55a2aefc74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c7dd2b8ef20490ab51be86ebcf87661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22d5607a80914565b9dd156f5886aa25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f55eca51936443cb73b993f926b664e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "473da0adee8f4896a89a6d33dd2e12c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f55eca51936443cb73b993f926b664e",
      "max": 487,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_13e2ece863ab4aafa2856609e4c638b9",
      "value": 487
     }
    },
    "4bb515e60f5d43fbaa5a619748532d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_598d91ab711246869d3e7a762ed9fd96",
      "placeholder": "​",
      "style": "IPY_MODEL_ed112f1498364d3f804649c010d7b00d",
      "value": " 487/487 [15:16&lt;00:00,  1.82s/it]"
     }
    },
    "598d91ab711246869d3e7a762ed9fd96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c04633ddfd94e249f694899e7fe92c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22d5607a80914565b9dd156f5886aa25",
      "placeholder": "​",
      "style": "IPY_MODEL_eed090baffd24e7ca840fa288319d6e5",
      "value": "100%"
     }
    },
    "62e89b2b99dc45918e3e67e5feac836a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb9dbdd955ed4d82b3402f5d51932b3c",
       "IPY_MODEL_473da0adee8f4896a89a6d33dd2e12c8",
       "IPY_MODEL_4bb515e60f5d43fbaa5a619748532d53"
      ],
      "layout": "IPY_MODEL_897595ff039c4a4eb780eadda659f379"
     }
    },
    "6e690f5786944587a13c8d40a4845422": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84a5fd78892943f49ff5ef20bd9b71a2",
      "placeholder": "​",
      "style": "IPY_MODEL_74d760f96f6241efbd576ad6b4519ba0",
      "value": " 52155/52155 [01:22&lt;00:00, 720.86it/s]"
     }
    },
    "74d760f96f6241efbd576ad6b4519ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "771f925fcd46415180dfbf9455532447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_962d3ebb12f042f08325cb463824dba9",
      "placeholder": "​",
      "style": "IPY_MODEL_fa3796ae730f4bb086280940b2b1219b",
      "value": "100%"
     }
    },
    "822165b974a141e2a3096426cec62fd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84a5fd78892943f49ff5ef20bd9b71a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "897595ff039c4a4eb780eadda659f379": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "962d3ebb12f042f08325cb463824dba9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aabf2644c2cc4066b968e3b0e5688015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_822165b974a141e2a3096426cec62fd5",
      "max": 52155,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d08ca546c039454e870e447ba29a39b4",
      "value": 52155
     }
    },
    "accf79d761fc4725bb64039726cddc3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c04633ddfd94e249f694899e7fe92c1",
       "IPY_MODEL_aabf2644c2cc4066b968e3b0e5688015",
       "IPY_MODEL_6e690f5786944587a13c8d40a4845422"
      ],
      "layout": "IPY_MODEL_f6f4e8bdf99c4fc2938842cbcdcf47b8"
     }
    },
    "bb9dbdd955ed4d82b3402f5d51932b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf37292b079649b38c2dd2ba2f64971d",
      "placeholder": "​",
      "style": "IPY_MODEL_c43283d0d53c44f8b7c0f52fd525e2d9",
      "value": "100%"
     }
    },
    "c43283d0d53c44f8b7c0f52fd525e2d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf37292b079649b38c2dd2ba2f64971d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d00765b03f484b27b3f63beffccfa084": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee29fa17894c46299513789a18b8ab2e",
      "placeholder": "​",
      "style": "IPY_MODEL_1c7b5d36c2444b1ba2a1ea55a2aefc74",
      "value": " 52155/52155 [01:20&lt;00:00, 683.26it/s]"
     }
    },
    "d08ca546c039454e870e447ba29a39b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da6b5510d5c1486abe82f8453e602fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd2eba11b1bf42258f01897da34ef0cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_771f925fcd46415180dfbf9455532447",
       "IPY_MODEL_fcd464cbac9945da8e158798466a26e7",
       "IPY_MODEL_d00765b03f484b27b3f63beffccfa084"
      ],
      "layout": "IPY_MODEL_1c7dd2b8ef20490ab51be86ebcf87661"
     }
    },
    "ed112f1498364d3f804649c010d7b00d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee29fa17894c46299513789a18b8ab2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed090baffd24e7ca840fa288319d6e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efee0ce5457d48b2ac72398cf1a60f7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6f4e8bdf99c4fc2938842cbcdcf47b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3796ae730f4bb086280940b2b1219b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcd464cbac9945da8e158798466a26e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efee0ce5457d48b2ac72398cf1a60f7d",
      "max": 52155,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da6b5510d5c1486abe82f8453e602fe7",
      "value": 52155
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
